---
title: "Using the dimension package"
author: "Wenlan Zang and Michael J. Kane"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using the dimension package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
header-includes:
  - \usepackage[ruled,vlined,linesnumbered]{algorithm2e}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7, 
  fig.height = 5
)
```

## Introduction

The R `dimension` package provides an efficient way to determine the dimension of a signal rich subspace in a large matrix. It also provides a cleaned estimator of the original matrix and correlation matrix. Source code is maintained at [https://github.com/WenlanzZ/dimension](https://github.com/WenlanzZ/dimension).

The `dimension` package estimates the intrinsic dimension of a signal-rich subspace in large, high-dimensional matrix "real- and complex value dense R matrices and real-valued saprse matrices from the `Matrix` package by decomposing matrix into a signal-plus-noise space and approximate the signal-rich subspace with a rank $K$ approximation $\hat{X}=\sum_{k=1}^{K}d_ku_k{v_k}^T$. We propose a procedure to estimate the rank $K$ of a matrix thereby retaining components whose variation is greater than that of random matrices, whose eigenvalues follow a universal Marc\u{e}nko-Pastur distribution.

The package included the following main functions:

- subspace() - Greate a subspace class with scaled eigenvalue and eigenvectors and simulated noise eigenvalues for specified ranks.
- print.subspace()- Get a brief summary of subspace class.
- plot.subspace() - Get the scree plot of subspace class.
- dimension() - Get the dimension of a signal-subspace in a large, high-dimensional matrix.
- clipped() - Get a cleaned estimator of the original matrix, its covairance matrix and correlation matrix.
- print.subspace_clipped() - Get a brief summary of the subspace_clipped class.
- modified\_legacyplot() - Produces modified summary plots of bcp() output.

A demostration of the main functions with a brief sample is as follow.

## IPF Single Cell Altas 
The IPF Single Cell Altas (`lung`) data can be found on GEO (GSE136831) which was examined  by [Adamset  al.(2019)](https://www.biorxiv.org/content/10.1101/759902v1.full.pdf) to build a single cell atlas of Idiopathic Pulmonary Fibrosis (IPF). It contains the gene expression of 312,928 cells profiled from "distal lung parenchyma samples obtained from 32 IPF, 18 chronic obstructive pulmonary disease (COPD) and 29 control donor lungs" (Adamset al.2019). 







When applied to a subgroup of control lung sample "001C", `dimension` estimated a signal dimension of 12. Figure 1 shows that the majority of signals can be captured up to dimension 12 and there are some sub signals up to dimension 18 and 28. Figure 2 further confirmed that major features for cell type clustering depends on dimension 1 to 12 and there is no cluster formed from dimension 13 to 50. 

The `subspace()` function will utilize `irlba` to calculate the first few approximate largest singular values and singular vectors. According to `irlba`, it uses about 1/20 elapsed time compared to the `svd` method and less than 1/3 the peak memory. Known that for a matrix $X_{n \times p}$, we can either do singular value decomposition $X=U\Sigma V^T$ or eigenvalue decomposition on $X^TX$ or $X^TX$ since $XX^T=U\Sigma^2U^T$ and $X^TX=V\Sigma^2V^T$. It also returns random generation for the Marc\u{e}nko-Pastur (MP) distribution with \pkg{RMTstat} \citep{MP}. To compare singular values of $X$ to random samples from MP distribution, we scale $\Sigma$ by dividing ${\beta p}$. When $n$ or $p$ is relatively large, it is necessary to speed up computation by splitting into {\tt times}-fold with \pkg{foreach} \citep{foreach}. Sampling from MP distribution, instead of calculating eigenvalues from random Gaussian matrix, is a strategy to avoid computer memory or power limitations. Thus, \pkg{dimension} is more scalable and computational efficient especially for large matrices. 

The following code shows how to simulate $x$ matrix of dimension $100 \times 150$ and construct a subspace with specified compoennts 1 to 50.

```{r}
setwd("/Users/wz262/Projects/dimension")
devtools::load_all()

#load matrix from Adamset al.2019
data(lung)
system.time({results <- dimension(lung, components = 1:50, times = 10)})
plot(results$Subspace, changepoint = results$dimension, annotation = 30)

# double check with Bayesian change point probability and posterior of change point probability
modified_legacyplot(results$Changepoint$bcp_irl)
modified_legacyplot(results$Changepoint$bcp_post)

# ladle estimator don't run - wait time long
# system.time({test1 <- ladle(x = lung, method = "pca")})
# ggplot() + geom_line(aes(x = 1:length(test1$gn), y = test1$gn), colour="black") +
#   geom_point(aes(x = 1:length(test1$gn), y = test1$gn), color = "red") +
#   ggtitle(paste0("The Ladle Plot", "\n", "n_", n, "_p_", p, "_d_", d, "_est d_", test1$d)) +
#   theme(plot.title = element_text(hjust = 0.5)) +
#   geom_text_repel(aes(x = 1:length(test1$gn), y = test1$gn, label = 1:length(test1$gn)), colour="black", size = 5) 

# Single cell RNA-Seq analysis with Seurat
library(Seurat)
lung <- CreateSeuratObject(counts = lung)
lung <- ScaleData(lung, do.scale = TRUE, do.center = TRUE)
lung <- FindVariableFeatures(lung)
lung <- RunPCA(lung, npcs = 50)

PCHeatmap(lung)
system.time({lung <- suppressWarnings(JackStraw(lung))})
head(lung@reductions$pca@jackstraw@empirical.p.values)
lung <- ScoreJackStraw(object = lung, dims = 1:20, reduction = "pca")
JackStrawPlot(object = lung, dims = 1:20, reduction = "pca")

lung <- RunUMAP(lung, method = 'umap-learn', reduction = "pca", dims = 1:50)

# louvain cluster based on features 1:50
lung <- FindNeighbors(lung, dims = 1:50)
lung <- FindClusters(lung, resolution = 0.8)
DimPlot(lung, reduction = "umap",label = TRUE)

# louvain cluster based on features 7:50
lung <- FindNeighbors(lung, dims = 7:50)
lung <- FindClusters(lung, resolution = 0.8)
DimPlot(lung, reduction = "umap",label = TRUE)

# louvain cluster based on features 1:6
lung <- FindNeighbors(lung, dims = 1:6)
lung <- FindClusters(lung, resolution = 0.8)
DimPlot(lung, reduction = "umap",label = TRUE)

# find marker genes for clusters
marker0 <- FindMarkers(lung, ident.1 = 0, only.pos = T)
marker1 <- FindMarkers(lung, ident.1 = 1, only.pos = T)
marker2 <- FindMarkers(lung, ident.1 = 2, only.pos = T)
marker3 <- FindMarkers(lung, ident.1 = 3, only.pos = T)

rownames(marker0[order(marker0$avg_logFC, decreasing = T),][1:20,])
rownames(marker1[order(marker1$avg_logFC, decreasing = T),][1:20,])
rownames(marker2[order(marker2$avg_logFC, decreasing = T),][1:20,])
rownames(marker3[order(marker3$avg_logFC, decreasing = T),][1:20,])

<<<<<<< HEAD
The package included the following main functions:

* subspace() - Greate a subspace class with scaled eigenvalue and eigenvectors and simulated noise eigenvalues for specified ranks.
* print.subspace()- Get a brief summary of subspace class.
* plot.subspace() - Get the scree plot of subspace class.
* dimension() - Get the dimension of a signal-subspace in a large high-dimensional matrix.
* clipped() - Get a cleaned estimator of the original matrix, its covairance matrix and correlation matrix.
* modified\_legacyplot() - Produces modified summary plots of bcp() output.

A demostration of the main functions and with a brief sample is as follow.

# Subspace

Let $x\in R^{n\times p}$ be a simulated multivariate normal matrix with $ncc$ correlated columns.

```{r setup}
library(devtools)
load_all()
x <- x_sim(n = 100, p = 150, ncc = 30, var = c(rep(10,5),rep(3,25)))
t1 <- proc.time()
Subspace <- subspace(x, components = 1:50, times = 10)
print(proc.time() - t1)
gc()
plot(Subspace, annotation = 30)
t2 <- proc.time()
results  <- dimension(subspace_ = Subspace)
# equivalently, if Subspace has not been calculated
results <- dimension(x, components = 1:50, times = 10)
print(proc.time() - t2)
gc()
str(results)
plot(results$Subspace, changepoint = results$dimension, annotation = 30)
modified_legacyplot(results$Changepoint$bcp_irl, annotation = 30)
modified_legacyplot(results$Changepoint$bcp_post, annotation = 30)
t3 <- proc.time()
TopSubspace <- subspace(x, components = 1:5, times = 10)
TopSubspace
MidSubspace <- subspace(x, components = 6:40, times = 10)
MidSubspace
print(proc.time() - t3)
gc()
plot(TopSubspace, changepoint = results$dimension, annotation = 5)
plot(MidSubspace, changepoint = results$dimension, annotation = 40)
```

=======
```

macrophage: "CCL4”,   "CCL4L2”, "CCL3L1”,  "IFNG”,   "CD69”,   "IL32”,   "GNLY”,   "GZMB”,   "KLRB1”,  "CCL3" 

Epithelial type 2 and club cell: "SCGB3A1”,  "SCGB1A1”,  "SFTPC”,    "SCGB3A2”,  "APOD”,  "SLPI”,  "DCN" ,  "SAA2”, "SFTPB" , "SFTPA2" 

Epithelial type 1: "AGER”,   "EMP2”,   "KRT7”,   "CAV1”,   "HOPX”,   "KRT19”,  "CLDN18”,  "CYP4B1”,  "DSTN”,   "CD55"


With the estimated $dimension$ output from `dimension()`, we can clip the scaled eigenvalues of $x$ in order to provide a cleaned estimator $e\_clipped$ of the underlying correlation matrix and $x\_clipped$ of the original matrix. Proceeds by keeping the $N * \alpha$ top eigenvalues and shrinking the remaining ones by a trace-preserving constant (i.e. $Tr(E\_clipped) = Tr(E)$) or zeroing out remaining ones. This function `clipped()` is adapted from Python for Random Matrix Theory (GiecoldOuaknin2017).
```{r}
# x_clp <- clipped(x, components = 20, method = "threshold", alpha = 0.9, zeroout = TRUE)
# x_clp <- clipped(x, components = 20, method = "hard", zeroout = FALSE)
# # equivalently, if Subspace is calculated
# x_clp <- clipped(subspace_ = Subspace, method = "identity", location = c(1:5))
```

>>>>>>> e2e3f2f3fe27d2b26515e397dc1707cf8cc49841

